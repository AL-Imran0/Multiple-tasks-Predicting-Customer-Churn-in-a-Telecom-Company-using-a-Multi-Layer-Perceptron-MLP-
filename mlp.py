# -*- coding: utf-8 -*-
"""MLP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b_bbZ_Km1S-zhhSZ0-CgWEyK6xhOaWmr
"""

!pip install pandas numpy matplotlib seaborn scikit-learn keras tensorflow

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam
np.random.seed(42)
num_samples = 1000
customer_id = np.arange(1, num_samples + 1)
age = np.random.randint(18, 71, num_samples)
gender = np.random.randint(0, 2, num_samples)
tenure = np.random.randint(1, 72, num_samples)
monthly_charges = np.random.uniform(10, 120, num_samples)
contract = np.random.randint(0, 3, num_samples)
internet_service = np.random.randint(0, 3, num_samples)
churn = np.random.randint(0, 2, num_samples)

data = {
    'CustomerID': customer_id,
    'Age': age,
    'Gender': gender,
    'Tenure': tenure,
    'MonthlyCharges': monthly_charges,
    'Contract': contract,
    'InternetService': internet_service,
    'Churn': churn
}

df = pd.DataFrame(data)

print(df.head())

label_encoder = LabelEncoder()
df['Gender'] = label_encoder.fit_transform(df['Gender'])
df['Contract'] = label_encoder.fit_transform(df['Contract'])
df['InternetService'] = label_encoder.fit_transform(df['InternetService'])

X = df.drop(columns=['CustomerID', 'Churn'])
y = df['Churn']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

def build_mlp_model(input_dim, hidden_layers=[128, 64, 32], learning_rate=0.001):
    model = Sequential()
    model.add(Dense(hidden_layers[0], input_dim=input_dim, activation='relu'))
    model.add(Dense(hidden_layers[1], activation='relu'))
    model.add(Dense(hidden_layers[2], activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])
    return model

epochs = 100
batch_size = 32
learning_rate = 0.001

model = build_mlp_model(X_train_scaled.shape[1], hidden_layers=[128, 64, 32], learning_rate=learning_rate)

history = model.fit(X_train_scaled, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test_scaled, y_test))

plt.figure(figsize=(8, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training & Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

y_pred = (model.predict(X_test_scaled) > 0.5).astype("int32")

accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")

precision = precision_score(y_test, y_pred)
print(f"Precision: {precision:.4f}")

recall = recall_score(y_test, y_pred)
print(f"Recall: {recall:.4f}")

f1 = f1_score(y_test, y_pred)
print(f"F1-Score: {f1:.4f}")

conf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

fpr, tpr, thresholds = roc_curve(y_test, model.predict(X_test_scaled))
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

learning_rates = [0.0001, 0.001, 0.01]
batch_sizes = [16, 32, 64]

best_accuracy = 0
best_params = {}

for lr in learning_rates:
    for bs in batch_sizes:
        print(f"Training with lr={lr}, batch_size={bs}")

        model = build_mlp_model(X_train_scaled.shape[1], hidden_layers=[128, 64, 32], learning_rate=lr)
        history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=bs, validation_data=(X_test_scaled, y_test), verbose=0)

        y_pred = (model.predict(X_test_scaled) > 0.5).astype("int32")
        accuracy = accuracy_score(y_test, y_pred)

        print(f"Accuracy: {accuracy:.4f}")

        if accuracy > best_accuracy:
            best_accuracy = accuracy
            best_params = {'learning_rate': lr, 'batch_size': bs}

print(f"Best Hyperparameters: {best_params}")
print(f"Best Accuracy: {best_accuracy:.4f}")